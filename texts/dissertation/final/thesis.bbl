\begin{thebibliography}{40}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Cop()]{Copeland_2016}
What’s the difference between artificial intelligence, machine learning and
  deep learning?
\newblock URL
  \url{https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/}.

\bibitem[IBM()]{IBM_2021}
{IBM} - {Analytics} and {AI} architecture.
\newblock URL
  \url{https://www.ibm.com/cloud/architecture/architectures/aiAnalyticsArchitecture/reference-architecture/}.

\bibitem[MLS()]{MLSAS_2021}
Machine learning: o que é e qual sua importância?
\newblock URL
  \url{https://www.sas.com/pt_br/insights/analytics/machine-learning.html}.

\bibitem[MLW()]{MLWikipedia_2021}
Aprendizado de máquina.
\newblock URL \url{https://pt.wikipedia.org/wiki/Aprendizado_de_máquina}.

\bibitem[IBM(2005)]{IBM_2005}
An architectural blueprint for autonomic computing.
\newblock Technical report, IBM, 2005.
\newblock URL
  \url{https://www-03.ibm.com/autonomic/pdfs/AC%20Blueprint%20White%20Paper%20V7.pdf}.

\bibitem[Del(2018)]{Deloitte_2018}
Machine learning: things are getting intense, 2018.
\newblock URL
  \url{https://www2.deloitte.com/content/dam/Deloitte/global/Images/infographics/technologymediatelecommunications/gx-deloitte-tmt-2018-intense-machine-learning-report.pdf}.

\bibitem[CIO(2021)]{CIO_2021}
Brasil se destaca com 42\% das iniciativas de {IA} na {América Latina}, em
  2020, 2021.
\newblock URL
  \url{https://cio.com.br/tendencias/brasil-se-destaca-com-42-das-iniciativas-de-ia-na-america-latina-em-2020/}.

\bibitem[LGP(2021)]{LGPD_2021}
{Proteção de Dados - LGPD}, 2021.
\newblock URL
  \url{https://www.gov.br/defesa/pt-br/acesso-a-informacao/lei-geral-de-protecao-de-dados-pessoais-lgpd}.

\bibitem[Abbas et~al.(2010)Abbas, Andersson, and Löwe]{Abbas_2010}
Nadeem Abbas, Jesper Andersson, and Welf Löwe.
\newblock Autonomic software product lines.
\newblock pages 324--331, 2010.

\bibitem[Agarwal et~al.(2018)Agarwal, Beygelzimer, Dud{\'\i}k, Langford, and
  Wallach]{Agarwal_2018}
Alekh Agarwal, Alina Beygelzimer, Miroslav Dud{\'\i}k, John Langford, and Hanna
  Wallach.
\newblock A reductions approach to fair classification.
\newblock In \emph{International Conference on Machine Learning}, pages 60--69,
  2018.

\bibitem[Agarwal et~al.(2019)Agarwal, Dud{\'\i}k, and Wu]{Agarwal_2019}
Alekh Agarwal, Miroslav Dud{\'\i}k, and Zhiwei~Steven Wu.
\newblock Fair regression: Quantitative definitions and reduction-based
  algorithms.
\newblock In \emph{International Conference on Machine Learning}, pages
  120--129, 2019.

\bibitem[Arrieta et~al.(2020)Arrieta, Rodr{\'{\i}}guez, Ser, Bennetot, Tabik,
  Barbado, Garc{\'{\i}}a, Gil{-}Lopez, Molina, Benjamins, Chatila, and
  Herrera]{Arrieta_2020}
Alejandro~Barredo Arrieta, Natalia~D{\'{\i}}az Rodr{\'{\i}}guez, Javier~Del
  Ser, Adrien Bennetot, Siham Tabik, Alberto Barbado, Salvador Garc{\'{\i}}a,
  Sergio Gil{-}Lopez, Daniel Molina, Richard Benjamins, Raja Chatila, and
  Francisco Herrera.
\newblock Explainable artificial intelligence {(XAI):} concepts, taxonomies,
  opportunities and challenges toward responsible {AI}.
\newblock \emph{Information Fusion}, 58:\penalty0 82--115, 2020.

\bibitem[Begley et~al.(2021)Begley, Schwedes, Frye, and Feige]{Begley_2021}
Tom Begley, Tobias Schwedes, Christopher Frye, and Ilya Feige.
\newblock Explainability for fair machine learning, 2021.

\bibitem[Biswas and Rajan(2020)]{Biswas_2020}
Sumon Biswas and Hridesh Rajan.
\newblock Do the machine learning models on a crowd sourced platform exhibit
  bias? an empirical study on model fairness.
\newblock page 642–653, 2020.

\bibitem[Bosch(2004)]{Bosch_2004}
Jan Bosch.
\newblock Software architecture: The next step.
\newblock pages 194--199, 2004.

\bibitem[Buolamwini and Gebru(2018)]{Buolamwini_2018}
Joy Buolamwini and Timnit Gebru.
\newblock Gender shades: Intersectional accuracy disparities in commercial
  gender classification.
\newblock In \emph{Conference on Fairness, Accountability and Transparency},
  volume~81 of \emph{Proceedings of Machine Learning Research}, pages 77--91,
  2018.

\bibitem[Calmon et~al.(2017)Calmon, Wei, Vinzamuri, Natesan~Ramamurthy, and
  Varshney]{Calmon_2017}
Flavio Calmon, Dennis Wei, Bhanukiran Vinzamuri, Karthikeyan
  Natesan~Ramamurthy, and Kush~R Varshney.
\newblock Optimized pre-processing for discrimination prevention.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2017.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2017/file/9a49a25d845a483fae4be7e341368e36-Paper.pdf}.

\bibitem[Celis et~al.(2019)Celis, Huang, Keswani, and Vishnoi]{Celis_2019}
L~Elisa Celis, Lingxiao Huang, Vijay Keswani, and Nisheeth~K Vishnoi.
\newblock Classification with fairness constraints: A meta-algorithm with
  provable guarantees.
\newblock In \emph{Proceedings of the conference on fairness, accountability,
  and transparency}, pages 319--328, 2019.

\bibitem[d'Alessandro et~al.(2017)d'Alessandro, O'Neil, and
  LaGatta]{dAlessandro_2017}
Brian d'Alessandro, Cathy O'Neil, and Tom LaGatta.
\newblock Conscientious classification: A data scientist's guide to
  discrimination-aware classification.
\newblock \emph{Big Data}, pages 120--134, 2017.

\bibitem[Feldman et~al.(2015)Feldman, Friedler, Moeller, Scheidegger, and
  Venkatasubramanian]{Feldman_2015}
Michael Feldman, Sorelle~A. Friedler, John Moeller, Carlos Scheidegger, and
  Suresh Venkatasubramanian.
\newblock Certifying and removing disparate impact.
\newblock In \emph{Proceedings of the 21th ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, page 259–268, 2015.
\newblock URL \url{https://doi.org/10.1145/2783258.2783311}.

\bibitem[Fowler(2005)]{Fowler_2005}
Martin Fowler.
\newblock Fluentinterface, 2005.
\newblock URL \url{https://martinfowler.com/bliki/FluentInterface.html}.

\bibitem[Garlan and Shaw(1993)]{Garlan_1993}
David Garlan and Mary Shaw.
\newblock An introduction to software architecture.
\newblock In \emph{Advances in Software Engineering and Knowledge Engineering},
  1993.

\bibitem[Hardt et~al.(2016)Hardt, Price, Price, and Srebro]{Hardt_2016}
Moritz Hardt, Eric Price, Eric Price, and Nati Srebro.
\newblock Equality of opportunity in supervised learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2016/file/9d2682367c3935defcb1f9e247a97c0d-Paper.pdf}.

\bibitem[Kamiran and Calders(2011)]{Kamiran_2011}
Faisal Kamiran and Toon Calders.
\newblock Data pre-processing techniques for classification without
  discrimination.
\newblock \emph{Knowledge and Information Systems}, 2011.
\newblock URL
  \url{https://www.researchgate.net/publication/228975972_Data_Pre-Processing_Techniques_for_Classification_without_Discrimination}.

\bibitem[Kamiran et~al.(2012)Kamiran, Karim, and Zhang]{Kamiran_2012}
Faisal Kamiran, Asim Karim, and Xiangliang Zhang.
\newblock Decision theory for discrimination-aware classification.
\newblock In \emph{2012 IEEE 12th International Conference on Data Mining},
  pages 924--929, 2012.

\bibitem[Kapishnikov et~al.(2019)Kapishnikov, Bolukbasi, Vi{\'{e}}gas, and
  Terry]{Kapishnikov_2019}
Andrei Kapishnikov, Tolga Bolukbasi, Fernanda~B. Vi{\'{e}}gas, and Michael
  Terry.
\newblock {XRAI:} better attributions through regions.
\newblock In \emph{{IEEE/CVF} International Conference on Computer Vision},
  pages 4947--4956, 2019.

\bibitem[Kearns et~al.(2018)Kearns, Neel, Roth, and Wu]{Kearns_2018}
Michael Kearns, Seth Neel, Aaron Roth, and Zhiwei~Steven Wu.
\newblock Preventing fairness gerrymandering: Auditing and learning for
  subgroup fairness.
\newblock In \emph{International Conference on Machine Learning}, pages
  2564--2572, 2018.

\bibitem[Kephart and Chess(2003)]{Kephart_2003}
Jeffrey Kephart and D.M. Chess.
\newblock The vision of autonomic computing.
\newblock pages 41 -- 50, 2003.

\bibitem[Khalegi(2019{\natexlab{a}})]{Khalegi_2019}
Bahador Khalegi.
\newblock The how of explainable ai: Explainable modelling, 2019{\natexlab{a}}.
\newblock URL
  \url{https://towardsdatascience.com/the-how-of-explainable-ai-explainable-modelling-55c8c43d7bed}.

\bibitem[Khalegi(2019{\natexlab{b}})]{Khalegi_2019_Post}
Bahador Khalegi.
\newblock The how of explainable ai: Post-modelling explainability,
  2019{\natexlab{b}}.
\newblock URL
  \url{https://towardsdatascience.com/the-how-of-explainable-ai-post-modelling-explainability-8b4cbc7adf5f}.

\bibitem[Khalegi(2019{\natexlab{c}})]{Khalegi_2019_Pre}
Bahador Khalegi.
\newblock The how of explainable ai: Pre-modelling explainability,
  2019{\natexlab{c}}.
\newblock URL
  \url{https://towardsdatascience.com/the-how-of-explainable-ai-pre-modelling-explainability-699150495fe4}.

\bibitem[Maleki et~al.(2013)Maleki, Tran{-}Thanh, Hines, Rahwan, and
  Rogers]{Maleki_2013}
Sasan Maleki, Long Tran{-}Thanh, Greg Hines, Talal Rahwan, and Alex Rogers.
\newblock Bounding the estimation error of sampling-based shapley value
  approximation with/without stratifying.
\newblock 2013.

\bibitem[Mehrabi et~al.(2021)Mehrabi, Morstatter, Saxena, Lerman, and
  Galstyan]{Mehrabi_2021}
Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram
  Galstyan.
\newblock A survey on bias and fairness in machine learning.
\newblock \emph{ACM Computing Surveys}, pages 1--35, 2021.

\bibitem[Mougan et~al.(2022)Mougan, {\'{A}}lvarez, Patro, Ruggieri, and
  Staab]{Mougan_2022}
Carlos Mougan, Jos{\'{e}}~Manuel {\'{A}}lvarez, Gourab~K. Patro, Salvatore
  Ruggieri, and Steffen Staab.
\newblock Fairness implications of encoding protected categorical attributes.
\newblock 2022.

\bibitem[Nakamaru and Chiba(2020)]{Nakamaru_2020}
Tomoki Nakamaru and Shigeru Chiba.
\newblock Generating a generic fluent api in java.
\newblock \emph{The Art, Science, and Engineering of Programming}, 2020.
\newblock URL
  \url{http://dx.doi.org/10.22152/programming-journal.org/2020/4/9}.

\bibitem[Pleiss et~al.(2017)Pleiss, Raghavan, Wu, Kleinberg, and
  Weinberger]{Pleiss_2017}
Geoff Pleiss, Manish Raghavan, Felix Wu, Jon Kleinberg, and Kilian~Q
  Weinberger.
\newblock On fairness and calibration.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2017.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2017/file/b8b9c74ac526fffbeb2d39ab038d1cd7-Paper.pdf}.

\bibitem[Speicher et~al.(2018)Speicher, Heidari, Grgic-Hlaca, Gummadi, Singla,
  Weller, and Zafar]{Speicher_2018}
Till Speicher, Hoda Heidari, Nina Grgic-Hlaca, Krishna~P. Gummadi, Adish
  Singla, Adrian Weller, and Muhammad~Bilal Zafar.
\newblock A unified approach to quantifying algorithmic unfairness.
\newblock 2018.
\newblock URL \url{http://dx.doi.org/10.1145/3219819.3220046}.

\bibitem[Sundararajan et~al.(2017)Sundararajan, Taly, and
  Yan]{Sundararajan_2017}
Mukund Sundararajan, Ankur Taly, and Qiqi Yan.
\newblock Axiomatic attribution for deep networks.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning}, volume~70 of \emph{Proceedings of Machine Learning Research},
  pages 3319--3328, 2017.

\bibitem[Zemel et~al.(2013)Zemel, Wu, Swersky, Pitassi, and Dwork]{Zemel_2013}
Rich Zemel, Yu~Wu, Kevin Swersky, Toni Pitassi, and Cynthia Dwork.
\newblock Learning fair representations.
\newblock In \emph{Proceedings of the 30th International Conference on Machine
  Learning}, pages 325--333, 2013.
\newblock URL \url{https://proceedings.mlr.press/v28/zemel13.html}.

\bibitem[Zhang et~al.(2018)Zhang, Lemoine, and Mitchell]{Zhang_2018}
Brian Zhang, Blake Lemoine, and Margaret Mitchell.
\newblock Mitigating unwanted biases with adversarial learning.
\newblock pages 335--340, 2018.
\newblock URL
  \url{https://www.researchgate.net/publication/330299272_Mitigating_Unwanted_Biases_with_Adversarial_Learning}.

\end{thebibliography}
